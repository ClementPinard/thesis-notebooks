{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_direct_warp.direct_warp import DirectWarper\n",
    "from pytorch_direct_warp.occlusion_mapper import OcclusionMapper\n",
    "from utils import inverse_warp, pixel2cam, pose_vec2mat, cam2pixel\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import animation, rc\n",
    "import matplotlib.colors as colors\n",
    "from imageio import imread\n",
    "from skimage.transform import resize\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from IPython.display import HTML\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "torch.no_grad()\n",
    "plt.rcParams[\"figure.figsize\"] = [12,9]\n",
    "h=200\n",
    "f = h/2\n",
    "batch_size = 1\n",
    "\n",
    "def truncate_colormap(cmap, minval=0.0, maxval=1.0, n=100):\n",
    "    new_cmap = colors.LinearSegmentedColormap.from_list(\n",
    "        'trunc({n},{a:.2f},{b:.2f})'.format(n=cmap.name, a=minval, b=maxval),\n",
    "        cmap(np.linspace(minval, maxval, n)), gamma=0.8)\n",
    "    return new_cmap\n",
    "\n",
    "cmap = plt.get_cmap('gist_rainbow')\n",
    "new_cmap = truncate_colormap(cmap, 0, 0.85)\n",
    "\n",
    "intrinsics = torch.Tensor([[f, 0, h/2],\n",
    "                           [0, f, h/2],\n",
    "                           [0,  0,  1]]).float().to(device).unsqueeze(0)\n",
    "intrinsics_inv = torch.inverse(intrinsics[0]).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg_depth = 1\n",
    "bg_depth = 10\n",
    "\n",
    "fg_pos = [50, 50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "foreground = resize(imread('img/foreground.jpg'), (h//2,h//2))\n",
    "fg_tensor = torch.from_numpy(foreground.transpose(2,0,1)).float().to(device)\n",
    "background = resize(imread('img/background.jpg'),(h,h))\n",
    "bg_tensor = torch.from_numpy(background.transpose(2,0,1)).float().to(device)\n",
    "img = bg_tensor.clone().unsqueeze(0)\n",
    "temp_h, temp_w = fg_pos\n",
    "img[:,:, temp_h:temp_h + h//2, temp_w:temp_w + h//2] = fg_tensor\n",
    "depth = (torch.zeros(1,h,h) + bg_depth).float().to(device)\n",
    "depth[:, temp_h:temp_h + h//2, temp_w:temp_w + h//2] = fg_depth\n",
    "depth +=  0.001*torch.randn(1,h,h).to(device)\n",
    "#line = torch.linspace(-h/2,h/2,h).abs().to(device)\n",
    "#depth += line\n",
    "#parabola = 0.1*(line.view(1,1,h) + line.view(1,h,1))\n",
    "#depth = parabola\n",
    "\n",
    "plt.figure(figsize=(12,9))\n",
    "plt.subplot(121)\n",
    "plt.imshow(img[0].permute(1,2,0).cpu().numpy())\n",
    "plt.subplot(122)\n",
    "plt.imshow(depth[0].cpu().numpy(), cmap=new_cmap, vmin=0, vmax=10)\n",
    "plt.colorbar(fraction=0.046, pad=0.04)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Warping on a vector pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#you can define different poses to see how the warping behaves\n",
    "pose = torch.Tensor([0.2, 0.2, 0, 0, 0, 0]).unsqueeze(0).to(device).expand(batch_size, 6)\n",
    "\n",
    "\n",
    "matrix = pose_vec2mat(pose)\n",
    "warper = DirectWarper()\n",
    "warped, wimg = warper(depth, img, matrix, intrinsics, 0)\n",
    "# warped[:,20:40, 20:40] = warped[:, 20:40,20:40] * 0 + torch.linspace(100,10,20).view(1,1,-1).to(device)\n",
    "plt.figure(figsize = (12,9), dpi=100)\n",
    "plt.subplot(121)\n",
    "plt.imshow(wimg[0].cpu().permute(1,2,0))\n",
    "plt.subplot(122)\n",
    "plt.imshow(warped[0].cpu(),cmap=new_cmap)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,9))\n",
    "\n",
    "warped, wimg = warper(depth, img, matrix, intrinsics, 0)\n",
    "warped = warped.cpu()\n",
    "wimg = wimg[0].permute(1,2,0).cpu()\n",
    "plt.subplot(121)\n",
    "im1 = plt.imshow(warped[0].numpy(), animated=True, vmin=0, vmax=10,cmap=new_cmap)\n",
    "plt.subplot(122)\n",
    "im2 = plt.imshow(wimg.numpy(), animated=True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "x = np.linspace(0, 2*np.pi, 100)\n",
    "def animate(i):\n",
    "    pose = torch.Tensor([0*np.sin(x[i]) , 0*np.cos(x[i]), 0.5*np.cos(x[i]), 0.5*np.cos(x[i]), 0, x[i]]).view(1,6).to(device).expand(batch_size, 6)\n",
    "    pose_mat = pose_vec2mat(pose)\n",
    "    \n",
    "    warped, wimg = warper(depth, img, pose_mat, intrinsics, 0)\n",
    "    im1.set_array(warped[0].cpu().numpy())\n",
    "    im2.set_array(wimg[0].permute(1,2,0).cpu().numpy())\n",
    "    return (im1,im2)\n",
    "animate(0)\n",
    "\n",
    "ani = animation.FuncAnimation(fig, animate, interval=50, blit=True)\n",
    "\n",
    "HTML(ani.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Occlusion module\n",
    "\n",
    "This figure decompose the different techniques to get the occlusion map for a particular depth map + a pose.\n",
    "The video is optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(3,3,figsize=(16,20),sharex=True,sharey=True)\n",
    "noise = 0.1 * torch.randn(1,h,h).to(device)\n",
    "noisy_depth = depth + noise\n",
    "im_list = []\n",
    "ax_list = axes.reshape(-1)\n",
    "i = 0\n",
    "warper = DirectWarper(keep_index=True)\n",
    "\n",
    "def draw_map(ax, dmap, title):\n",
    "    im = ax.imshow(dmap.cpu()[0], animated=True, vmin=0, vmax=10, cmap=new_cmap)\n",
    "    ax.set_title(title, fontsize=20, y=1.05)\n",
    "    return im\n",
    "\n",
    "im0 = draw_map(ax_list[0], depth, '$\\\\theta_t$')\n",
    "im1 = draw_map(ax_list[1], depth, '$\\\\theta_{t+1}$')\n",
    "im2 = draw_map(ax_list[2], depth, 'valid pixels of $\\\\theta_t$ \\n (pixels not occluded in $\\\\theta_{t+1}$)')\n",
    "\n",
    "warped_back = '\\widetilde{\\\\nu}_{t \\\\rightarrow t+1 \\\\rightarrow t}'\n",
    "range_alpha = '\\\\left[\\\\frac{1}{2}\\\\nu_t, 2\\\\nu_t\\\\right]'\n",
    "p = '\\\\mathbf{p}'\n",
    "\n",
    "im3 = draw_map(ax_list[3], noisy_depth, 'Noisy depth $\\\\nu_t $')\n",
    "im4 = draw_map(ax_list[4], noisy_depth, 'Warped depth $\\widetilde{\\\\nu}_{t \\\\rightarrow t+1}$')\n",
    "im5 = draw_map(ax_list[5], noisy_depth, 'Indexed back depth \\n'\n",
    "                                         '$\\\\lbrace\\\\nu_t(\\\\mathbf{p}),\\\\mathbf{p} \\in Id \\\\rbrace$')\n",
    "im6 = draw_map(ax_list[6], noisy_depth, 'Warped back depth ${}$'.format(warped_back))\n",
    "im7 = draw_map(ax_list[7], noisy_depth, '$\\\\lbrace\\\\nu_t, {wb} \\in {ra} \\\\rbrace$'.format(p=p, wb=warped_back, ra=range_alpha))\n",
    "im8 = draw_map(ax_list[8], noisy_depth, '$\\\\lbrace\\\\nu_t, {wb} \\in {ra} \\\\rbrace$\\n'\n",
    "    '+ erosion of $2$'.format(p=p, wb=warped_back, ra=range_alpha))\n",
    "\n",
    "cbar_ax = fig.add_axes([0.2, 0.1, 0.6, 0.01])\n",
    "plt.colorbar(im0, cax=cbar_ax, orientation='horizontal')\n",
    "\n",
    "\n",
    "x = np.linspace(0, 2*np.pi, 100)\n",
    "\n",
    "def animate(i):\n",
    "    pose = torch.Tensor([0.5*np.sin(x[i]) , 0.5*np.cos(x[i]), 0.5*np.cos(x[i]), 0, 0.*np.cos(x[i]), 0.*x[i]]).view(1,6).to(device).expand(batch_size, 6)\n",
    "    pose_mat = pose_vec2mat(pose)\n",
    "    inverse_rot = pose_mat[:,:,:3].transpose(1,2)\n",
    "    inverse_tr = -inverse_rot @ pose_mat[:,:,-1:]\n",
    "    inverse_pose_mat = torch.cat([inverse_rot, inverse_tr], dim=-1)\n",
    "    \n",
    "    #construct theoretical warped and occlusion maps, with no noise\n",
    "    mapper = OcclusionMapper(dilation=1, alpha = 100)\n",
    "    warped = warper(depth, None, pose_mat, intrinsics, 0)\n",
    "    occlusion = mapper(depth, pose_mat, intrinsics)\n",
    "    \n",
    "    #do the same, but with a noisy depth\n",
    "    mapper = OcclusionMapper(dilation=0, alpha=2)\n",
    "    warped_noisy = warper(noisy_depth, None, pose_mat, intrinsics, 0)\n",
    "    warped_back_noisy = warper(warped_noisy, None, inverse_pose_mat, intrinsics, 0)\n",
    "    \n",
    "    mapper = OcclusionMapper(dilation=0, alpha=2)\n",
    "    occlusion_noisy = mapper(noisy_depth, pose_mat, intrinsics)\n",
    "    \n",
    "    mapper = OcclusionMapper(dilation=2, alpha=2)\n",
    "    occlusion_noisy_eroded = mapper(noisy_depth, pose_mat, intrinsics)\n",
    "    \n",
    "    depth_occ = depth.clone()\n",
    "    depth_occ[occlusion] = float('inf')\n",
    "    \n",
    "    depth_occ_noisy = noisy_depth.clone()\n",
    "    depth_occ_noisy[occlusion_noisy] = float('inf')\n",
    "    \n",
    "    depth_occ_noisy2 = noisy_depth.clone()\n",
    "    depth_occ_noisy2[occlusion_noisy_eroded] = float('inf')\n",
    "    \n",
    "    warper(noisy_depth, None, pose_mat, intrinsics, 0)\n",
    "    index = warper.index\n",
    "    id_map = torch.full_like(noisy_depth, float('inf'))\n",
    "    id_map.view(-1).index_copy_(0, index[index>=0], (warped_noisy - pose[0,2])[index>=0])\n",
    "    \n",
    "    im1.set_array(warped.cpu()[0])\n",
    "    im2.set_array(depth_occ.cpu()[0])\n",
    "    im4.set_array(warped_noisy.cpu()[0])\n",
    "    im5.set_array(id_map.cpu()[0])\n",
    "    im6.set_array(warped_back_noisy.cpu()[0])\n",
    "    im7.set_array(depth_occ_noisy.cpu()[0])\n",
    "    im8.set_array(depth_occ_noisy2.cpu()[0])\n",
    "    return (im1,im2,im3,im4,im5)\n",
    "\n",
    "animate(37)\n",
    "fig.subplots_adjust(hspace=0.1,wspace=0.1)\n",
    "plt.show()\n",
    "\n",
    "ani = animation.FuncAnimation(fig, animate, interval=50, blit=True)\n",
    "\n",
    "HTML(ani.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

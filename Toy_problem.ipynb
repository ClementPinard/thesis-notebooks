{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "from utils import inverse_warp, pixel2cam, pose_vec2mat, cam2pixel, invert_mat\n",
    "from loss_functions import TV_loss, TVV_loss, diffusion_loss, grad_diffusion_loss, robust_diffusion_loss, robust_grad_diffusion_loss\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import animation, rc\n",
    "import matplotlib.colors as colors\n",
    "from labellines import labelLine, labelLines\n",
    "from itertools import cycle\n",
    "from matplotlib.pyplot import subplot2grid, subplots_adjust\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from imageio import imread\n",
    "from skimage.transform import resize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import pickle\n",
    "\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "h = 200\n",
    "f = h//2\n",
    "bg_depth=10\n",
    "\n",
    "def truncate_colormap(cmap, minval=0.0, maxval=1.0, n=100):\n",
    "    new_cmap = colors.LinearSegmentedColormap.from_list(\n",
    "        'trunc({n},{a:.2f},{b:.2f})'.format(n=cmap.name, a=minval, b=maxval),\n",
    "        cmap(np.linspace(minval, maxval, n)))\n",
    "    return new_cmap\n",
    "\n",
    "cmap = plt.get_cmap('gist_rainbow')\n",
    "new_cmap = truncate_colormap(cmap, 0, 0.85)\n",
    "\n",
    "intrinsics = torch.Tensor([[f, 0, f],\n",
    "                           [0, f, f],\n",
    "                           [0,  0,  1]]).float().unsqueeze(0).to(device)\n",
    "intrinsics_inv = torch.inverse(intrinsics[0]).unsqueeze(0)\n",
    "\n",
    "#print(intrinsics)\n",
    "#print(intrinsics_inv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing image tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_scene(name, real_texture=True):\n",
    "    global intrinsics, intrinsics_inv\n",
    "    if name == 'occ':\n",
    "        pose = torch.Tensor([1/10, 1/10, 0, 0, 0, 0]).view(1,6).to(device)\n",
    "        pose_matrix = pose_vec2mat(pose)\n",
    "        transfer_matrix = intrinsics@(torch.cat([pose_matrix[:,:,:3]@intrinsics_inv, pose_matrix[:,:,-1:]], dim=-1))\n",
    "        inv_pose_matrix = invert_mat(pose_matrix)\n",
    "\n",
    "        fg_depth = 1\n",
    "        fg_init_pos = [50, 50]\n",
    "\n",
    "        fg_displacement = transfer_matrix[0,:2,-1]/fg_depth\n",
    "        bg_displacement = transfer_matrix[0,:2,-1]/bg_depth\n",
    "\n",
    "        real_texture = True\n",
    "        if real_texture:\n",
    "            foreground = resize(imread('img/foreground.jpg'), (h//2, h//2))\n",
    "            fg_tensor = torch.from_numpy(foreground.transpose(2,0,1)).float().to(device)\n",
    "\n",
    "            background = resize(imread('img/background.jpg'),(h + 2*bg_displacement[0].item(),h + 2*bg_displacement[1].item()))\n",
    "            bg_tensor = torch.from_numpy(background.transpose(2,0,1)).float().to(device)\n",
    "        else:\n",
    "            fg_tensor = ((torch.linspace(-1, 1, h//2)**2).view(1,1,h//2) + (torch.linspace(-1, 1, h//2)**2).view(1,h//2,1)).expand(3,h//2,h//2).to(device)\n",
    "            fg_tensor = fg_tensor * 0.5\n",
    "            fg_tensor[0] = 1\n",
    "\n",
    "            h1 = h + 2*int(bg_displacement[0])\n",
    "            h2 = h + 2*int(bg_displacement[1])\n",
    "            bg_tensor = ((torch.linspace(-1, 1, h1)**2).view(1,1,h1) + (torch.linspace(-1, 1, h2)**2).view(1,h2,1)).expand(3,h2,h1).to(device)\n",
    "            bg_tensor = bg_tensor * 0.5\n",
    "            bg_tensor[1] = 0\n",
    "\n",
    "        temp_h, temp_w = bg_displacement\n",
    "        img1 = bg_tensor[:,int(temp_h):-int(temp_h),int(temp_h):-int(temp_h)].clone().unsqueeze(0)\n",
    "        temp_h, temp_w = fg_init_pos\n",
    "        img1[:,:, temp_h:temp_h + h//2, temp_w:temp_w + h//2] = fg_tensor\n",
    "        depth1 = (torch.zeros(1,h,h) + bg_depth).float().to(device)\n",
    "        depth1[:, temp_h:temp_h + h//2, temp_w:temp_w + h//2] = fg_depth\n",
    "\n",
    "        temp_h, temp_w = bg_displacement\n",
    "        img2 = bg_tensor.clone()[:, :h, :h].unsqueeze(0)\n",
    "        temp_h, temp_w = int(fg_init_pos[0] + fg_displacement[0]), int(fg_init_pos[1] + fg_displacement[1])\n",
    "        img2[:,:, temp_h:temp_h + h//2, temp_w:temp_w + h//2] = fg_tensor.unsqueeze(0)\n",
    "        depth2 = (torch.zeros(1,h,h) + bg_depth).float().to(device)\n",
    "        depth2[:, temp_h:temp_h + h//2, temp_h:temp_h + h//2] = 1\n",
    "\n",
    "\n",
    "        temp_h, temp_w = bg_displacement\n",
    "        img3 = bg_tensor.clone()[:, -h:, -h:].unsqueeze(0)\n",
    "        temp_h, temp_w = int(fg_init_pos[0] - fg_displacement[0]), int(fg_init_pos[1] - fg_displacement[1])\n",
    "        img3[:,:, temp_h:temp_h + h//2, temp_w:temp_w + h//2] = fg_tensor.unsqueeze(0)\n",
    "        depth3 = (torch.zeros(1,h,h) + bg_depth).float().to(device)\n",
    "        depth3[:, temp_h:temp_h + h//2, temp_h:temp_h + h//2] = 1\n",
    "    elif name == 'plane':\n",
    "        pose = torch.Tensor([0,0,0.2,0,0,0]).view(1,6).to(device)\n",
    "        pose_matrix = pose_vec2mat(pose)\n",
    "        transfer_matrix = intrinsics@(torch.cat([pose_matrix[:,:,:3]@intrinsics_inv, pose_matrix[:,:,-1:]], dim=-1))\n",
    "        inv_pose_matrix = invert_mat(pose_matrix)\n",
    "\n",
    "        from torch.nn.functional import interpolate\n",
    "        img1 = resize(imread('img/plane0.jpg'), (h, h))\n",
    "        img1 = torch.from_numpy(img1.transpose(2,0,1)).float().to(device).unsqueeze(0)\n",
    "        img2 = resize(imread('img/plane1.jpg'), (h, h))\n",
    "        img2 = torch.from_numpy(img2.transpose(2,0,1)).float().to(device).unsqueeze(0)\n",
    "        img3 = resize(imread('img/plane-1.jpg'), (h, h))\n",
    "        img3 = torch.from_numpy(img3.transpose(2,0,1)).float().to(device).unsqueeze(0)\n",
    "\n",
    "        depthmaps = [np.load('img/plane{}.npy'.format(suffix)) for suffix in ['0','1','-1']]\n",
    "        depth_stacked = 0.1*np.stack(depthmaps)\n",
    "        depth_tensor = torch.from_numpy(depth_stacked).float().to(device).unsqueeze(1)\n",
    "        depth_tensor.clamp_(0,bg_depth)\n",
    "        depth_tensor = interpolate(depth_tensor, (h,h), mode='area')\n",
    "        depth1, depth2, depth3 = depth_tensor\n",
    "    elif name == 'both':\n",
    "        imgs1, depths1, poses1 = setup_scene('occ', real_texture)\n",
    "        imgs2, depths2, poses2 = setup_scene('plane')\n",
    "        img1, img2, img3 = (torch.cat(pair) for pair in zip(imgs1, imgs2))\n",
    "        depth1, depth2, depth3 = (torch.cat(pair) for pair in zip(depths1, depths2))\n",
    "        pose, pose_matrix, inv_pose_matrix, transfer_matrix = (torch.cat(pair) for pair in zip(poses1, poses2))\n",
    "        intrinsics = intrinsics.expand(2,3,3)\n",
    "        intrinsics_inv = intrinsics_inv.expand(2,3,3)\n",
    "    return (img1, img2, img3), (depth1, depth2, depth3), (pose, pose_matrix, inv_pose_matrix, transfer_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(img1, img2, img3), (depth1, depth2, depth3), (pose, pose_matrix, inv_pose_matrix, transfer_matrix) = setup_scene('both')\n",
    "plt.figure(dpi=300,figsize = [10,10])\n",
    "plt.subplot(131)\n",
    "plt.imshow(img2[0].permute(1,2,0).cpu().numpy())\n",
    "plt.title('$I_{t-1}$')\n",
    "plt.subplot(132)\n",
    "plt.imshow(img1[0].permute(1,2,0).cpu().numpy())\n",
    "plt.title('$I_t$')\n",
    "plt.subplot(133)\n",
    "plt.imshow(img3[0].permute(1,2,0).cpu().numpy())\n",
    "plt.title('$I_{t+1}$')\n",
    "plt.show()\n",
    "plt.figure(dpi=100, figsize = (10,10))\n",
    "plt.subplot(131)\n",
    "plt.imshow(depth1[0].cpu().numpy(), cmap=new_cmap)\n",
    "plt.title('$\\\\theta_t$')\n",
    "plt.colorbar(fraction=0.046, pad=0.04)\n",
    "# plt.subplot(132)\n",
    "# plt.imshow(depth2[0].cpu().numpy(), cmap='jet')\n",
    "# plt.colorbar(fraction=0.046, pad=0.04)\n",
    "# plt.subplot(133)\n",
    "# plt.imshow(depth3[0].cpu().numpy(), cmap='jet')\n",
    "# plt.colorbar(fraction=0.046, pad=0.04)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverse warp illustration\n",
    "\n",
    "From now on, we call the function `inverse_warp`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_coords = pixel2cam(depth1)\n",
    "pose_mat = pose_vec2mat(pose)\n",
    "rot = intrinsics @ pose_mat[:,:,:3] @ intrinsics_inv\n",
    "tr = intrinsics @ pose_mat[:,:,-1:]\n",
    "src_pixel_coords = cam2pixel(cam_coords, rot, tr)\n",
    "projected_img = torch.nn.functional.grid_sample(img2, src_pixel_coords)\n",
    "real_coords = 0.5*(src_pixel_coords + 1) * h\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(121)\n",
    "plt.imshow(img1[0].cpu().permute(1,2,0))\n",
    "plt.title('$I_t$')\n",
    "plt.subplot(122)\n",
    "plt.imshow(img2[0].cpu().permute(1,2,0))\n",
    "plt.title(\"$I_{t-1}$\")\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(projected_img[0].cpu().permute(1,2,0))\n",
    "plt.title(\"Inverse warping of $I_{t-1}$ to look like $I_t$\")\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(131)\n",
    "plt.imshow(real_coords[0,:,:,0].cpu(),cmap='jet',vmax=h)\n",
    "plt.colorbar(fraction=0.046, pad=0.04)\n",
    "plt.title(\"u coordinates of $I_{t-1}$\\n pixels into $I_t$ frame\")\n",
    "plt.subplot(132)\n",
    "plt.imshow(real_coords[0,:,:,1].cpu(),cmap='jet',vmax=h)\n",
    "plt.colorbar(fraction=0.046, pad=0.04)\n",
    "plt.title(\"v coordinates of $I_{t-1}$\\n pixels into $I_t$ frame\")\n",
    "plt.subplot(133)\n",
    "plt.imshow(projected_img[0].cpu().permute(1,2,0))\n",
    "plt.title(\"Inverse warping of $I_{t-1}$\\n to look like $I_t$\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The occlusion problem\n",
    "\n",
    "diff map is not entirely black even though the depth maps is perfect !\n",
    "\n",
    "Second diff map is not entirely black either, but the occluded artea are not the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img2_warped = inverse_warp(img2, depth1, pose_matrix, intrinsics)\n",
    "img3_warped = inverse_warp(img3, depth1, inv_pose_matrix, intrinsics)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(221)\n",
    "plt.imshow(img2_warped[0].cpu().permute(1,2,0).numpy())\n",
    "plt.title(\"$I_{t-1}$ to $I_t$\")\n",
    "plt.subplot(222)\n",
    "plt.imshow(img3_warped[0].cpu().permute(1,2,0).numpy())\n",
    "plt.title(\"$I_{t+1}$ to $I_t$\")\n",
    "plt.subplot(223)\n",
    "plt.imshow((img2_warped - img1)[0].abs().cpu().permute(1,2,0).numpy())\n",
    "plt.subplot(224)\n",
    "plt.imshow((img3_warped - img1)[0].abs().cpu().permute(1,2,0).numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smooth depth or disp ?\n",
    "\n",
    "Plane sample from Blender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imageio import imread\n",
    "pic = imread('img/plane0.jpg')\n",
    "dmap = np.clip(np.load('img/plane0.npy'),0,250)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(121)\n",
    "plt.imshow(pic)\n",
    "plt.subplot(122)\n",
    "plt.imshow(dmap, cmap=new_cmap, vmin=0, vmax=100)\n",
    "plt.colorbar(fraction=0.046, pad=0.04)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(2,1,figsize=(5,5),dpi=100,\n",
    "                        sharex=True,sharey=False)\n",
    "axes[0].plot(dmap[::-1,0])\n",
    "axes[0].set_ylim((0, 200))\n",
    "axes[0].set_ylabel('depth $\\theta$ ($m$)')\n",
    "axes[1].plot(1/dmap[::-1,0])\n",
    "axes[1].set_ylabel(\"$\\\\xi$ = 1/depth ($m^{-1}$)\")\n",
    "plt.xlabel('pixel')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Optimization\n",
    "\n",
    "You can play with the 6 different smooth loss to see how differently it behaves.\n",
    "\n",
    "You can also try the occlusion mapper and the minimum loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loss_functions import TV_loss, TVV_loss, diffusion_loss, grad_diffusion_loss, robust_diffusion_loss, robust_grad_diffusion_loss\n",
    "from pytorch_direct_warp.occlusion_mapper import OcclusionMapper\n",
    "mapper = OcclusionMapper(dilation=1, alpha=2)\n",
    "\n",
    "def apply_smooth_loss(mode, xi, img1, weight, kappa):\n",
    "    if mode == 'TV':\n",
    "        return weight * TV_loss(xi, img1, kappa)\n",
    "    elif mode == 'TVV':\n",
    "        return weight * TVV_loss(xi, img1, kappa)\n",
    "    elif mode == \"regular_diff\":\n",
    "        return weight * diffusion_loss(xi, img1, kappa).mean()\n",
    "    elif mode == \"robust_diff\":\n",
    "        return weight * robust_diffusion_loss(xi, img1, kappa, gamma=0.1, iterations=10).mean()\n",
    "    elif mode == 'regular_grad_diff':\n",
    "        return weight * grad_diffusion_loss(xi, img1, kappa)\n",
    "    elif mode == 'robust_grad_diff':\n",
    "        return weight * robust_grad_diffusion_loss(xi, img1, kappa, gamma=0.1, iterations=10).mean()\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def one_iteration(depth, img1, img2, img3,\n",
    "                  pose_matrix, inv_pose_matrix,\n",
    "                  intrinsics, intrinsics_inv,\n",
    "                  smooth_mode='TV', weight=0, kappa=50,\n",
    "                  occluded=False, minloss=False):\n",
    "    projected_img2 = inverse_warp(img2, depth, pose_matrix, intrinsics)\n",
    "    projected_img3 = inverse_warp(img3, depth, inv_pose_matrix, intrinsics)\n",
    "    diff_map2 = (projected_img2 - img1).abs().mean(dim=1, keepdim=True)\n",
    "    diff_map3 = (projected_img3 - img1).abs().mean(dim=1, keepdim=True)\n",
    "    if occluded:\n",
    "        occlusion2 = mapper(depth, pose_matrix, intrinsics).unsqueeze(1)\n",
    "        diff_map2 *= (1 - occlusion2.float())\n",
    "\n",
    "        occlusion3 = mapper(depth, inv_pose_matrix, intrinsics).unsqueeze(1)\n",
    "        diff_map3 *= (1 - occlusion3.float())\n",
    "        with torch.no_grad():\n",
    "            to_return = projected_img2* (1 - occlusion2).float(), projected_img3* (1 - occlusion3).float()\n",
    "    else:\n",
    "        to_return = projected_img2, projected_img3\n",
    "    if minloss:\n",
    "        diff_map = torch.stack([diff_map2, diff_map3])\n",
    "        loss = 2*torch.min(diff_map, dim=0)[0].mean()\n",
    "    else:\n",
    "        diff_map = diff_map2 + diff_map3\n",
    "        loss = diff_map.mean()\n",
    "        \n",
    "    \n",
    "    xi = 1/depth.unsqueeze(1)\n",
    "    \n",
    "    loss += apply_smooth_loss(smooth_mode, xi, img1, weight, kappa)\n",
    "        \n",
    "    return (loss, *to_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance(estimation, target, first_estimation):\n",
    "    b, *_ = estimation.shape\n",
    "    logdiff = (torch.log(estimation) - torch.log(target)).view(b,-1).abs().mean(dim=1)\n",
    "    logdiff0 = (torch.log(first_estimation) - torch.log(target)).view(b,-1).abs().mean(dim=1)\n",
    "    return 1 - (logdiff/logdiff0).clamp(max=1)\n",
    "\n",
    "@torch.no_grad()\n",
    "def joint_performance(*args):\n",
    "    perf = performance(*args)\n",
    "    return torch.sqrt(perf.prod()).item()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video\n",
    "\n",
    "This will display the evolution of the optimization\n",
    "\n",
    "If occlusion module is selected, discarded areas will appear black\n",
    "\n",
    "(NB: you must have ffmpeg to make this cell work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from torch.nn.functional import interpolate\n",
    "from tqdm import tqdm\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "frames = 100\n",
    "scene_to_show = 0\n",
    "\n",
    "inv_pose_matrix = invert_mat(pose_matrix)\n",
    "depth_param = torch.nn.Parameter(bg_depth*torch.ones_like(depth1).to(device))\n",
    "optimizer = torch.optim.Adam([depth_param], lr=0.15, betas=[0.9, 0.999])\n",
    "\n",
    "ax1 = fig.add_subplot(221)\n",
    "depth_plot = plt.imshow(depth_param[scene_to_show].cpu().detach().numpy(),\n",
    "                        animated=True, cmap=new_cmap, vmin=0, vmax=bg_depth)\n",
    "plt.title(\"$\\widetilde{\\\\theta}_t$\")\n",
    "\n",
    "divider = make_axes_locatable(ax1)\n",
    "cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "fig.colorbar(depth_plot, cax=cax, orientation='vertical')\n",
    "\n",
    "ax2 = fig.add_subplot(222)\n",
    "depth_diff = plt.imshow((depth1 - depth_param)[scene_to_show].cpu().detach().numpy(),\n",
    "                        animated=True, cmap='seismic_r', vmin=-10, vmax=10)\n",
    "plt.title(\"$\\\\theta_t - \\widetilde{\\\\theta}_t$\")\n",
    "divider = make_axes_locatable(ax2)\n",
    "cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "fig.colorbar(depth_diff, cax=cax, orientation='vertical')\n",
    "\n",
    "plt.subplot(223)\n",
    "img_warped2 = inverse_warp(img2, depth_param, pose_matrix, intrinsics)\n",
    "img_warped2_plot = plt.imshow(img_warped2[scene_to_show].detach().cpu().permute(1,2,0).numpy(), animated=True)\n",
    "plt.title(\"$\\widetilde{\\\\mathbf{I}}_{t-1 \\\\rightarrow t}$\")\n",
    "plt.subplot(224)\n",
    "img_warped3 = inverse_warp(img3, depth_param, inv_pose_matrix, intrinsics)\n",
    "img_warped3_plot = plt.imshow(img_warped3[scene_to_show].detach().cpu().permute(1,2,0).numpy(), animated=True)\n",
    "plt.title(\"$\\widetilde{\\\\mathbf{I}}_{t+1 \\\\rightarrow t}$\")\n",
    "losses = []\n",
    "\n",
    "def animate(i):\n",
    "    global depth_param\n",
    "    #depth_param = disp_param\n",
    "    for j in range(100):\n",
    "        loss, proj_img2, proj_img3 = one_iteration(depth_param, img1, img2, img3,\n",
    "                                                   pose_matrix, inv_pose_matrix,\n",
    "                                                   intrinsics, intrinsics_inv,\n",
    "                                                   smooth_mode = 'regular_diff',\n",
    "                                                   weight=1, kappa=0.3, occluded=True, minloss=False)\n",
    "        if loss.item() != loss.item():\n",
    "            print('nan')\n",
    "        with torch.no_grad():\n",
    "            losses.append((torch.log(depth_param)-torch.log(depth1))[0].abs().mean().item())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        with torch.no_grad():\n",
    "            depth_param.clamp_(min=1e-3)\n",
    "\n",
    "\n",
    "    depth_plot.set_array(depth_param[scene_to_show].detach().cpu().numpy())\n",
    "    depth_diff.set_array((depth1 - depth_param)[scene_to_show].detach().cpu().numpy())\n",
    "    img_warped2_plot.set_array(proj_img2[scene_to_show].detach().cpu().permute(1,2,0).numpy())\n",
    "    img_warped3_plot.set_array(proj_img3[scene_to_show].detach().cpu().permute(1,2,0).numpy())\n",
    "    return (depth_plot, depth_diff, img_warped2_plot, img_warped3_plot)\n",
    "ani = animation.FuncAnimation(fig, animate, interval=100, frames=frames, blit=True)\n",
    "HTML(ani.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# quantitative comparison\n",
    "\n",
    "5 different smooth loss are tested, smooth loss is applied on disparity (1/depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_optim(frames=10000, lr=0.15, verbose=True, **params):\n",
    "    b, *_ = depth1.shape\n",
    "    depth_param = torch.nn.Parameter(bg_depth*torch.ones_like(depth1).to(device))\n",
    "    optimizer = torch.optim.Adam([depth_param], lr=lr, betas=[0.9, 0.999])\n",
    "    losses = []\n",
    "    perf = []\n",
    "    if verbose:\n",
    "        iterator = tqdm(range(frames), desc='{}, k={}'.format(params['smooth_mode'], params['kappa']))\n",
    "    else:\n",
    "        iterator = range(frames)\n",
    "    for i in iterator:\n",
    "        loss, proj_img2, proj_img3 = one_iteration(depth_param, img1, img2, img3,\n",
    "                                                   pose_matrix, inv_pose_matrix,\n",
    "                                                   intrinsics, intrinsics_inv,\n",
    "                                                   **params)\n",
    "        diff = (torch.log(depth1) - torch.log(depth_param)).detach().view(b,-1).abs().mean(dim=1).cpu()\n",
    "        losses.append(diff)\n",
    "        perf.append(joint_performance(depth_param, depth1, torch.tensor(bg_depth, dtype=torch.float)))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        with torch.no_grad():\n",
    "            depth_param.clamp_(min=1e-3)\n",
    "    losses = torch.stack(losses, dim=1)  # [B, N]\n",
    "    results = depth_param.detach().cpu().numpy()\n",
    "    return [losses, perf, results]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ideal hyperparameters without occlusion module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "No occ\n",
    "                             Best HPs         M   Delta M  LE Flower  LE Plane\n",
    "loss                                                                          \n",
    "TV                           (3, 0.1)  0.324930 -0.467036   0.393109  0.740419\n",
    "TVV                          (1, 1.0)  0.300545 -0.353216   0.352660  0.851164\n",
    "diffusion                   (30, 0.3)  0.667593 -0.305300   0.163082  0.419741\n",
    "robust diffusion           (100, 0.3)  0.687293 -0.673019   0.122136  0.444456\n",
    "gradient diffusion          (30, 0.3)  0.544494 -0.115311   0.320266  0.368213\n",
    "robust gradient diffusion  (100, 1.0)  0.570228 -0.138599   0.267509  0.435731\n",
    "'''\n",
    "\n",
    "overall_losses = {}\n",
    "overall_losses['nothing'] = one_optim(smooth_mode='nothing', weight=0, kappa=50)\n",
    "overall_losses['TV'] = one_optim(smooth_mode = 'TV', weight=1, kappa=0.8)\n",
    "overall_losses['TVV'] = one_optim(smooth_mode = 'TVV', weight=1, kappa=3.0)\n",
    "overall_losses['diffusion'] = one_optim(smooth_mode = 'regular_diff', weight=30, kappa=0.3)\n",
    "overall_losses['robust diffusion'] = one_optim(smooth_mode = 'robust_diff', weight=100, kappa=0.3)\n",
    "overall_losses['robust gradient diffusion'] = one_optim(smooth_mode='robust_grad_diff', weight=30, kappa=0.3)\n",
    "overall_losses['gradient diffusion'] = one_optim(smooth_mode='regular_grad_diff', weight=30, kappa=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ideal hyperparameters *with* occlusion module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "with Occ\n",
    "                             Best HPs         M   Delta M  LE Flower  LE Plane\n",
    "loss                                                                          \n",
    "TV                           (1, 0.1)  0.629256 -0.444953   0.239570  0.357171\n",
    "TVV                        (0.1, 0.3)  0.742534 -0.156344   0.161252  0.259845\n",
    "diffusion                    (1, 0.3)  0.856226 -1.052482   0.103939  0.116923\n",
    "robust diffusion             (1, 1.0)  0.838911 -0.621033   0.141725  0.073666\n",
    "gradient diffusion         (0.3, 0.3)  0.775137 -0.151047   0.173361  0.155664\n",
    "robust gradient diffusion  (0.3, 0.3)  0.764900 -0.141016   0.196597  0.123738\n",
    "\n",
    "'''\n",
    "overall_occ_losses = {}\n",
    "overall_occ_losses['nothing'] = one_optim(smooth_mode='nothing', weight=0, kappa=50, occluded=True)\n",
    "overall_occ_losses['TV'] = one_optim(smooth_mode = 'TV', weight=1, kappa=0.1, occluded=True)\n",
    "overall_occ_losses['TVV'] = one_optim(smooth_mode = 'TVV', weight=0.1, kappa=0.3, occluded=True)\n",
    "overall_occ_losses['diffusion'] = one_optim(smooth_mode = 'regular_diff', weight=1, kappa=0.3, occluded=True)\n",
    "overall_occ_losses['robust diffusion'] = one_optim(smooth_mode = 'robust_diff', weight=1, kappa=1.0, occluded=True)\n",
    "overall_occ_losses['robust gradient diffusion'] = one_optim(smooth_mode='robust_grad_diff', weight=0.3, kappa=0.3, occluded=True)\n",
    "overall_occ_losses['gradient diffusion'] = one_optim(smooth_mode='regular_grad_diff', weight=0.3, kappa=0.3, occluded=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Displaying Result\n",
    "\n",
    "You can decide which result to display. If you want to compare occluded and not occluded, see next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "linestyles = ['-', '--', '-.', ':']\n",
    "with_occ=True\n",
    "\n",
    "losses = overall_occ_losses if with_occ else overall_losses\n",
    "\n",
    "plt.figure(figsize=(20,10), dpi=100)\n",
    "for (loss_name, loss) ,style in zip(losses.items(), cycle(linestyles)):\n",
    "    #print(loss[1])\n",
    "    plt.plot(loss[1], label=loss_name, linestyle=style)\n",
    "labelLines(plt.gca().get_lines(),align=False,fontsize=14)\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('$\\mathcal{M}$')\n",
    "plt.show()\n",
    "\n",
    "for scene , name in zip([0,1], [\"Flower\", \"Horizon\"]):\n",
    "    fig1, ax1 = plt.subplots(figsize=(20,10), dpi=100)\n",
    "    for (loss_name, loss) ,style in zip(losses.items(), cycle(linestyles)):\n",
    "        ax1.plot(loss[0][scene].numpy(), label=loss_name, linestyle=style)\n",
    "    plt.legend(loc=1)\n",
    "    xvals = [6000,1800,3000,850,3000,1500,1500,1500,3500,2000,7000]\n",
    "    xvals=None\n",
    "    #xvals = range(0, 10*len(overall_losses.keys()), 100)\n",
    "    labelLines(plt.gca().get_lines(),align=False,fontsize=10,xvals=xvals)\n",
    "    plt.xlabel('iterations')\n",
    "    plt.ylabel('log error ($LE$)')\n",
    "    plt.title('log error ($LE$) on {} scene ({} occlusion filtering)'.format(name, \"with\" if with_occ else \"no\"))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    fig = plt.figure(figsize=(15,15))\n",
    "    subplots_adjust(wspace=0,hspace=0)\n",
    "    num_plots = len(losses.keys()) + 1\n",
    "    grid = int(num_plots//3) + 1\n",
    "    ax = subplot2grid((grid,6), (0, 1), colspan=2)\n",
    "    plt.imshow( depth1.cpu().numpy()[scene], cmap=new_cmap, vmin=0, vmax=bg_depth)\n",
    "    plt.title('groundtruth')\n",
    "\n",
    "    ax = subplot2grid((grid,6), (0,3), colspan=2)\n",
    "    #result = losses['nothing']\n",
    "    #plt.imshow( result[2][scene], cmap=new_cmap, vmin=0, vmax=bg_depth)\n",
    "    plt.title('nothing')\n",
    "\n",
    "    for i, (loss_name, result) in enumerate(losses.items()):\n",
    "        if 'nothing' not in loss_name:\n",
    "            plt.subplot(grid, 3, i+3)\n",
    "            plt.imshow( result[2][scene], cmap=new_cmap, vmin=0, vmax=bg_depth)\n",
    "            plt.title(loss_name)\n",
    "    plt.tight_layout()\n",
    "    cbar_ax = fig.add_axes([0.85, 0.685, 0.015, 0.29])\n",
    "    plt.colorbar(cax=cbar_ax)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison between occluded and not occluded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from labellines import labelLine, labelLines\n",
    "from itertools import cycle\n",
    "import matplotlib\n",
    "plt.rcParams[\"figure.figsize\"] = [20,10]\n",
    "linestyles = ['-', '--', '-.', ':']\n",
    "loss_to_test = ['gradient diffusion', 'diffusion']\n",
    "for scene, name in zip([0,1], [\"Flower\", \"Horizon\"]):\n",
    "    fig1, ax1 = plt.subplots()\n",
    "    for (loss_name, loss) ,style in zip(overall_occ_losses.items(), cycle(linestyles)):\n",
    "        if loss_to_test is None or loss_name in loss_to_test:\n",
    "            ax1.plot(loss[0][scene].numpy(), label=loss_name+ '_occ', linestyle=style)\n",
    "    for (loss_name, loss) ,style in zip(overall_losses.items(), cycle(linestyles)):\n",
    "        if loss_to_test is None or loss_name in loss_to_test:\n",
    "            ax1.plot(loss[0][scene].numpy(), label=loss_name, linestyle=style)\n",
    "    plt.legend()\n",
    "    labelLines(plt.gca().get_lines(),align=True,fontsize=14)\n",
    "    plt.title(\"Logarithmic error ($LE$) on {} scene\".format(name))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "for (loss_name, loss) ,style in zip(overall_losses.items(), cycle(linestyles)):\n",
    "    if loss_to_test is None or loss_name in loss_to_test:\n",
    "        plt.plot(loss[1], label=loss_name, linestyle=style)\n",
    "for (loss_name, loss) ,style in zip(overall_occ_losses.items(), cycle(linestyles)):\n",
    "    if loss_to_test is None or loss_name in loss_to_test:\n",
    "        plt.plot(loss[1], label=loss_name + '_occ', linestyle=style)\n",
    "labelLines(plt.gca().get_lines(),align=False,fontsize=14)\n",
    "plt.legend()\n",
    "plt.title(\"Quality measure $\\mathcal{M}$ on both scenes\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "for (loss_name, loss) ,style in zip(overall_losses.items(), cycle(linestyles)):\n",
    "    if loss_to_test is None or loss_name in loss_to_test:\n",
    "        loss1 = loss[1]\n",
    "        loss2 = overall_occ_losses[loss_name][1]\n",
    "        diff = [l1 - l2 for (l1,l2) in zip(loss1, loss2)]\n",
    "        plt.plot(diff, label=loss_name, linestyle=style)\n",
    "labelLines(plt.gca().get_lines(),align=False,fontsize=14)\n",
    "plt.legend()\n",
    "plt.title(\"Loss/Loss_occ difference comparison\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from labellines import labelLine, labelLines\n",
    "from itertools import cycle\n",
    "import pickle\n",
    "weights = [0.01,0.03,0.1,0.3,1,3,10,30,100,300,1000,3000,10000,30000]\n",
    "kappas = [0.01,0.03,0.1,0.3,1.0,3.0,100.0]\n",
    "\n",
    "def test_weights(smooth_mode, kappa):\n",
    "    maps = []\n",
    "    final_losses_list = []\n",
    "    for w in tqdm(weights):\n",
    "        losses, result = one_optim(smooth_mode=smooth_mode, weight=w, kappa=kappa, verbose=False, frames=1000, lr=0.05)\n",
    "        final_losses = losses[:,-1]\n",
    "        final_losses_list.append(final_losses)\n",
    "        maps.append(result)\n",
    "    losses = torch.stack(final_losses_list, dim=1)\n",
    "    losses_norm = (losses/losses[:,:1]).clamp(max=1)\n",
    "    optimal = 1 - (1-losses_norm).prod(dim=0, keepdim=True)\n",
    "    losses = torch.cat((losses, optimal))\n",
    "    x = torch.argmin(losses, dim=-1)\n",
    "    results = {'errors': losses, 'best_results': maps[x[-1].item()], 'minima': x}\n",
    "    return results\n",
    "\n",
    "def test_kappas(smooth_mode, weight):\n",
    "    maps = []\n",
    "    final_losses_list = []\n",
    "    for k in tqdm(kappas):\n",
    "        losses, result = one_optim(smooth_mode=smooth_mode, weight=weight, kappa=k, verbose=False, frames=10000, lr=0.05)\n",
    "        final_losses = losses[:,-1]\n",
    "        final_losses_list.append(final_losses)\n",
    "        maps.append(result)\n",
    "    losses = torch.stack(final_losses_list, dim=1)\n",
    "    losses_norm = (losses/losses[:,:1]).clamp(max=1)\n",
    "    optimal = 1 - (1-losses_norm).prod(dim=0, keepdim=True)\n",
    "    losses = torch.cat((losses, optimal))\n",
    "    x = torch.argmin(losses, dim=-1)\n",
    "    results = {'errors': losses, 'best_results': maps[x[-1].item()], 'minima': x}\n",
    "    return results\n",
    "\n",
    "def test_both(smooth_mode,occluded=False):\n",
    "    perf_tensor = torch.zeros((len(weights), len(kappas), 3))\n",
    "    result_maps = torch.zeros_like(depth1)\n",
    "    with tqdm(total = len(weights)*len(kappas)) as pbar:\n",
    "        for i,k in enumerate(kappas):\n",
    "            for j,w in enumerate(weights):\n",
    "                pbar.update(1)\n",
    "                losses, perf, result = one_optim(smooth_mode=smooth_mode,\n",
    "                                                 weight=w, kappa=k,\n",
    "                                                 verbose=False, frames=5000, lr=0.15,\n",
    "                                                 occluded=occluded)\n",
    "                perf_tensor[j,i,0] = perf[-1]\n",
    "                perf_tensor[j,i,1:] = losses[:,-1]\n",
    "                if perf[-1] > perf_tensor[:,:,0].max():\n",
    "                    result_maps = result\n",
    "    idx = torch.argmax(perf_tensor[:,:,0])\n",
    "    i,j = idx//len(kappas), idx%len(kappas)\n",
    "    w,k = weights[i], kappas[j]\n",
    "    return {'errors': perf_tensor, 'best_results': result_maps, 'minima': (w,k)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's search !\n",
    "\n",
    "(NB: this will take 12hours with occlusion module and without)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperp = {}\n",
    "hyperp['TV'] = test_both('TV')\n",
    "hyperp['TVV'] = test_both('TVV')\n",
    "\n",
    "hyperp['diffusion'] = test_both('regular_diff')\n",
    "hyperp['robust diffusion'] = test_both('robust_diff')\n",
    "\n",
    "hyperp['gradient diffusion'] = test_both('regular_MD_diff')\n",
    "hyperp['robust gradient diffusion'] = test_both('robust_MD_diff')\n",
    "\n",
    "with open('both_scenes_10000.pickle', 'wb') as handle:\n",
    "    pickle.dump(hyperp, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperp_occ = {}\n",
    "hyperp_occ['TV'] = test_both('TV', occluded=True)\n",
    "hyperp_occ['TVV'] = test_both('TVV', occluded=True)\n",
    "\n",
    "hyperp_occ['diffusion'] = test_both('regular_diff', occluded=True)\n",
    "hyperp_occ['robust diffusion'] = test_both('robust_diff', occluded=True)\n",
    "\n",
    "hyperp_occ['gradient diffusion'] = test_both('regular_MD_diff', occluded=True)\n",
    "hyperp_occ['robust gradient diffusion'] = test_both('robust_MD_diff', occluded=True)\n",
    "\n",
    "with open('both_scenes_occ_10000.pickle', 'wb') as handle:\n",
    "    pickle.dump(hyperp_occ, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display hyper parameter search results\n",
    "\n",
    "this will read files saved above in order to not have to run it each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with_occ = True\n",
    "hyperp_file = 'both_scenes{}_10000.pickle'.format(\"_occ\" if with_occ else \"\")\n",
    "\n",
    "with open(hyperp_file, 'rb') as handle:\n",
    "    to_display = pickle.load(handle)\n",
    "\n",
    "result_table = []\n",
    "max_error_occ = 0\n",
    "max_error_plane = 0\n",
    "for loss, result in to_display.items():\n",
    "    a = result['errors'].numpy()\n",
    "    perf_tensor = a[:,:,0]\n",
    "    errors_occ = a[:,:,1]\n",
    "    errors_plane = a[:,:,2]\n",
    "    \n",
    "    max_error_occ = max(max_error_occ, errors_occ.max())\n",
    "    max_error_plane = max(max_error_plane, errors_plane.max())\n",
    "    \n",
    "    id = list(np.unravel_index(np.argmax(perf_tensor), perf_tensor.shape))\n",
    "    id = (max(min(id[0], perf_tensor.shape[0]-2), 1), max(min(id[1], perf_tensor.shape[1]-2), 1))\n",
    "    \n",
    "    delta = -4*perf_tensor[id] + perf_tensor[id[0]+1, id[1]] + perf_tensor[id[0]-1, id[1]] + perf_tensor[id[0], id[1]-1] + perf_tensor[id[0], id[1]+1]\n",
    "    result_table.append([loss, (weights[id[0]], kappas[id[1]]), perf_tensor[id], delta, errors_occ[id], errors_plane[id]])\n",
    "\n",
    "result_table = pd.DataFrame(result_table, columns=['loss', 'Best HPs', 'M', 'Delta M', 'LE Flower', 'LE Plane'])\n",
    "print(result_table.set_index(\"loss\"))\n",
    "\n",
    "max_perf = result_table['M'].max()\n",
    "\n",
    "fig,axes = plt.subplots(2,3,figsize=(17,10),dpi=100,\n",
    "            sharex=True,sharey=True)\n",
    "\n",
    "er_fig, er_axes = plt.subplots(4,3,figsize=(17,20),dpi=100,\n",
    "            sharex=True,sharey=True)\n",
    "for i, (loss, result) in enumerate(to_display.items()):\n",
    "    perf_pos = (i%2, i//2)\n",
    "    error_pos = (2*(i//3), i%3)\n",
    "    a = result['errors'].numpy()\n",
    "    perf_tensor = a[:,:,0]\n",
    "    errors_occ = a[:,:,1]\n",
    "    errors_plane = a[:,:,2]\n",
    "    #print(a.shape)\n",
    "    X,Y = np.meshgrid(kappas, weights)\n",
    "    perf_ax = axes[perf_pos]\n",
    "    occ_ax = er_axes[error_pos]\n",
    "    plane_ax = er_axes[error_pos[0] + 1, error_pos[1]]\n",
    "    \n",
    "    im_perf = perf_ax.pcolor(X,Y,perf_tensor, vmin=0, vmax=max_perf, cmap='viridis')\n",
    "    im_occ_error = occ_ax.pcolor(X,Y, errors_occ, vmin=0, vmax=max_error_occ, cmap='magma')\n",
    "    im_plane_error = plane_ax.pcolor(X,Y, errors_plane, vmin=0, vmax=max_error_plane, cmap='magma')\n",
    "    perf_ax.set_xscale('log')\n",
    "    perf_ax.set_yscale('log')\n",
    "    occ_ax.set_xscale('log')\n",
    "    occ_ax.set_yscale('log')\n",
    "    plane_ax.set_xscale('log')\n",
    "    plane_ax.set_yscale('log')\n",
    "    \n",
    "    perf_ax.set_title(\"{} loss\".format(loss))\n",
    "    occ_ax.set_title(\"{} loss, Flower scene\".format(loss))\n",
    "    plane_ax.set_title(\"{} loss, Horizon scene\".format(loss))\n",
    "    \n",
    "    if (perf_pos[0] == 1):\n",
    "        axes[perf_pos].set_xlabel('$\\kappa$ weight')\n",
    "    if (perf_pos[1] == 0):\n",
    "        axes[perf_pos].set_ylabel('$\\lambda$ weight')\n",
    "    if (error_pos[0] == 2):\n",
    "        plane_ax.set_xlabel('$\\kappa$ weight')\n",
    "    if (error_pos[1] == 0):\n",
    "        occ_ax.set_ylabel('$\\lambda$ weight')\n",
    "        plane_ax.set_ylabel('$\\lambda$ weight')\n",
    "fig.subplots_adjust(right=0.8)\n",
    "cbar_ax = fig.add_axes([0.85, 0.15, 0.01, 0.7])\n",
    "fig.colorbar(im_perf, cax=cbar_ax)\n",
    "cbar_ax.set_title(\"$\\mathcal{M}$\")\n",
    "\n",
    "er_fig.subplots_adjust(right=0.8)\n",
    "cbar_ax = er_fig.add_axes([0.85, 0.15, 0.01, 0.7])\n",
    "er_fig.colorbar(im_occ_error, cax=cbar_ax)\n",
    "cbar_ax.set_title(\"$LE$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
